{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b55ae32-004d-47d8-b3c9-ffdb0fb6ae64",
   "metadata": {},
   "source": [
    "# Migrating Videos from StreamingVideoPlayer to Mux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c6aad-d540-4d2b-ae20-e1c37abfdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import json\n",
    "import time\n",
    "import urllib3\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "import csv\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacaef66-bd3f-4f94-a84b-e838fded819f",
   "metadata": {},
   "source": [
    "Generate Access Keys and Secret Tokens from the Mux Api settings using the following [guide](https://www.mux.com/docs/core/make-api-requests#http-basic-auth). Also, replace the svp usernames and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6bc58-c854-47a4-a496-15452e22c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mux_access_keys = <Access Keys>\n",
    "mux_secret_token = <Secret Token>\n",
    "svp_username = <SVP LOGIN EMAIL>\n",
    "svp_password = <SVP LOGIN PASSWORD>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e767d-efbe-49ea-8c7e-045177cc609e",
   "metadata": {},
   "source": [
    "Next, we need to set up web drivers due to the fact that svp doesn't have any publicly available apis that allow us to easily export the videos. We need to simulate human activity of\n",
    "1. logging into the platform\n",
    "2. Access the media files\n",
    "3. Download them\n",
    "\n",
    "We do not run it in headless mode completely because it's preferable to monitor the website to detect issues with it during crawling. \n",
    "One possible issue during crawling is that the algorithm for scrolling down the list fails at some point, so it's recommended to do it in intervals so one can easily detect issues. Experimentally, I found that crawling for 300 items at once is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85eec6-b392-4d3d-8994-9f8d6e8c951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "# options.add_argument(\"--headless\")  # Run browser in headless mode\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51257d0d-f337-4a34-a2c4-4aa913931230",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=options)  # Adjust for your browser/driver setup|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512174b-ef8c-4ba5-a54c-1079776da6cc",
   "metadata": {},
   "source": [
    "#### Algorithm for logging into streaming video provider\n",
    "\n",
    "A valid email and password needs to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2d4f9-2ddd-406b-b0a7-e7bd31c99aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_to_svp(driver, email, password):\n",
    "\n",
    "    def format_cookies(cookies):\n",
    "        return \";\".join([f\"{cookie['name']}={cookie['value']}\" for cookie in cookies])\n",
    "    \n",
    "    \"\"\"Logs into StreamingVideoProvider.\"\"\"\n",
    "    login_url = \"https://member.streamingvideoprovider.com\"  # Update if necessary\n",
    "    driver.get(login_url)\n",
    "     \n",
    "    time.sleep(30)\n",
    "\n",
    "    if \"#signIn\" in driver.current_url:\n",
    "        email_element = driver.find_element(By.CSS_SELECTOR, '[name=\"email\"]')\n",
    "        email_element.send_keys(email);\n",
    "    \n",
    "        pwd_element = driver.find_element(By.CSS_SELECTOR, '[name=\"password\"]')\n",
    "        pwd_element.send_keys(password);\n",
    "    \n",
    "        button_element = driver.find_element(By.ID, 'sign_in')\n",
    "        button_element.click()\n",
    "        time.sleep(20)\n",
    "\n",
    "    _cookies = format_cookies(driver.get_cookies())\n",
    "    return _cookies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60adfac2-a2a7-4073-9fb2-38b4634390f6",
   "metadata": {},
   "source": [
    "#### Algorithm for scrolling down the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bab59f-3a58-4a2a-a51e-cd9a5877bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_more_items(driver):\n",
    "    try:\n",
    "        load_more_button = driver.find_element(By.XPATH, '//svp-button[@label=\"Load more items\"]')            \n",
    "        load_more_button.click()\n",
    "        time.sleep(10)  # Allow time for the new items to load\n",
    "    except Exception as e:\n",
    "        print(\"No more items to load or button not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebc6ea-36dd-42a3-aaf9-11784dc2f6d4",
   "metadata": {},
   "source": [
    "#### Algorithm for fetching the clip id\n",
    "\n",
    "SVP has 2 different ids for marking the videos, the data_id is what's used in marking the videos for download, while the clip_id is what's used externally to mark the video e.g it's what's returned for storage in your application's db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c85489-8b84-44e0-9e26-b7be6ea24d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ids(driver, start_count):\n",
    "    for index in range(start_count+1, start_count+31):\n",
    "        row = driver.find_element(By.XPATH, f\"//tr[@data-index='{index}']\")\n",
    "        row.click()\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            data_id = row.get_attribute(\"data-id\")\n",
    "            clip_id = driver.find_element(By.CSS_SELECTOR, '[name=\"item_key\"]').text\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            clip_id = \"N/A\" \n",
    "        all_data_ids.append((data_id, clip_id))            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fcb6c-68e7-43e8-be34-4bb1daa1cd22",
   "metadata": {},
   "source": [
    "As mentioned earlier, there are usually issues when scrolling, so it makes sense to scroll through the list little by little. I scroll through the list 300 videos at a time, if an error arises, I make sure that the list is scrolled to the last entry, change the start_count of the process list to the next possible one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c921a5-c43d-4e40-96b4-0cb30b262c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07573158-2fb1-48c3-8357-2be925a368fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(start_count, item_count):\n",
    "    login_to_svp(driver, svp_username, svp_password)\n",
    "    i = start_count\n",
    "    while i <= item_count:\n",
    "        fetch_ids(driver, i)\n",
    "        load_more_items(driver)\n",
    "        print(\"section done\")\n",
    "        i += 30\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906559c-d0cc-4305-983f-62f65760067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process(0, 270)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366d80eb-1f50-4fa8-86c9-10cc1de4470e",
   "metadata": {},
   "source": [
    "Afterwards, we need to persist the data ids and clip ids to a file. This is also useful when we are crawling in intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716388eb-edfb-48db-9853-5b88783d1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_ids_to_csv(data_ids, file_name=\"data_ids_with_clip_ids.csv\"):\n",
    "    # Write the data IDs and clip IDs to a CSV file with a serial number\n",
    "    with open(file_name, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Number\", \"Data ID\", \"Clip ID\"])  # Write header row\n",
    "        for i, (data_id, clip_id) in enumerate(data_ids, start=1):\n",
    "            writer.writerow([i, data_id, clip_id])  # Write each row\n",
    "save_data_ids_to_csv(all_data_ids, file_name=\"data_ids_with_clip_ids_900-1000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4cb48-eba0-401e-9314-8f167fa87410",
   "metadata": {},
   "source": [
    "Next, we define the function for generating the download link when giving the data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1c340-fb80-4ad7-b22f-c11e18f6df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFile(data_id, cookies):    \n",
    "    response = requests.get(\n",
    "        f\"https://member.streamingvideoprovider.com/panel/server/deliveryClip?a=generateDownloadLink&clipId={data_id}&id={data_id}\",\n",
    "                                headers={\"Cookie\": cookies}, \n",
    "                                cookies = {cookie[\"name\"]: cookie[\"value\"] for cookie in driver.get_cookies()}\n",
    "    )\n",
    "    downloadLink = response.json()['dlLink']\n",
    "    return downloadLink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a028d841-5d81-4240-9238-614a4923bc7f",
   "metadata": {},
   "source": [
    "Afterwards, we need to find the file names, this can be generated directly from the download link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df230121-89b0-40a0-9de4-aa77bbac23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filename(url):\n",
    "        # Parse the URL\n",
    "        parsed_url = urlparse(url)\n",
    "        # Get query parameters as a dictionary\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        # Decode and extract the filename from 'response-content-disposition'\n",
    "        if 'response-content-disposition' in query_params:\n",
    "            disposition = query_params['response-content-disposition'][0]\n",
    "            # Look for 'filename=' in the content disposition\n",
    "            if 'filename=' in disposition:\n",
    "                filename = disposition.split('filename=')[-1]\n",
    "                # Decode URL-encoded filename\n",
    "                return unquote(filename).strip('\"')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3bad8-39ea-4462-930a-44367f017a28",
   "metadata": {},
   "source": [
    "Following this, we need to upload the videos to mux using the mux api. For this, we can pass the download link generated by svp directly into it, i.e we do not need to download the videos first before uploading them to mux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab907061-cba0-471e-9d89-840808c0f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mux_upload(file_name, mux_token_id, mux_token_secret):\n",
    "    url = \"https://api.mux.com/video/v1/assets\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"cors_origin\": \"*\",        \n",
    "        \"playback_policy\": [\"public\"],\n",
    "        \"video_quality\": \"basic\",\n",
    "        \"input\": [\n",
    "            {\n",
    "              \"url\": file_name\n",
    "            }\n",
    "          ],\n",
    "        \"passthrough\": extract_filename(file_name)\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Make the POST request\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        json=payload,\n",
    "        headers=headers,\n",
    "        auth=HTTPBasicAuth(mux_token_id, mux_token_secret),\n",
    "    )\n",
    "    jsonResponse = response.json()\n",
    "    return jsonResponse[\"data\"][\"id\"], jsonResponse[\"data\"][\"playback_ids\"][0][\"id\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35cfe9e-44f6-48d9-9c8c-1b453ae989f9",
   "metadata": {},
   "source": [
    "Now, we can begin to piece everything together, \n",
    "1. We read the rows from the csv file.\n",
    "2. Generate the download link for the row.\n",
    "3. Upload the video to mux\n",
    "4. Get the asset id, playback id fro mux\n",
    "5. And write everithing to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f2cb9-ab63-4491-ba0c-e61a08e72377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_ids(csv_file, upload_csv_file):\n",
    "    cookies = login_to_svp(driver, svp_username, svp_password)\n",
    "    rows = []\n",
    "    with open(csv_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "\n",
    "    for row in rows:\n",
    "        if 'Data ID' in row:            \n",
    "            file_name = downloadFile(row['Data ID'], cookies)                \n",
    "            assetId, playbackId = create_mux_upload(file_name, mux_access_keys, mux_secret_token)\n",
    "            row['Mux Asset ID'] = assetId\n",
    "            row['Mux Playback ID'] = playbackId\n",
    "            print(f\"Data Id: {row['Data ID']} done\")\n",
    "            \n",
    "    with open(upload_csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Number\", \"Data ID\", \"Clip ID\",'Mux Asset ID', 'Mux Playback ID'])\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write the updated rows\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70dd39-a1d6-48c9-8fdb-ef8195e2ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data_ids(\"data_ids_with_clip_ids_900-1000.csv\", \"mux_upload.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ad0e5-146c-4b5a-846b-7284eb6d91ad",
   "metadata": {},
   "source": [
    "#### Additional method of getting file names.\n",
    "\n",
    "Apart from the method earlier stated for extracting the file names, SVP also provides an endpoint for getting the title of the file as part of the video properties. \n",
    "\n",
    "We first need to generate the auth token using the svp api key and api code, that can be generated using the following [guide](https://help.streamingvideoprovider.com/en/articles/1356140-core-platform-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12247afd-d526-4fac-8bd5-e8e4851ccf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_token(api_key, api_code):\n",
    "    url = \"https://www.streamingvideoprovider.com/\"\n",
    "    params = {\n",
    "        \"l\": \"api\",\n",
    "        \"a\": \"svp_auth_get_token\",\n",
    "        \"api_key\": api_key,\n",
    "        \"api_code\": api_code,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise an error for HTTP response codes >= 400\n",
    "        return response.text  # Return the response as JSON\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0248d68-623d-4921-b69b-8fa0aeb453a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svp_api_key = <API KEY>\n",
    "svp_secret_code = <API CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c5121-2995-45a7-8e10-8f9309cef28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = get_auth_token(svp_api_key,svp_secret_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e6efe-36ed-4b42-9357-c2ce75b80267",
   "metadata": {},
   "source": [
    "Next, we define the function for extracting the video titles when given a video id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb3829-0793-498b-b29d-afb651646633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_properties(video_ref, token):\n",
    "    url = \"https://www.streamingvideoprovider.com/\"\n",
    "    params = {\n",
    "        \"l\": \"api\",\n",
    "        \"a\": \"svp_list_videos\",\n",
    "        \"token\": token,\n",
    "        \"video_ref\": video_ref,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status() \n",
    "        return  xmltodict.parse(response.text)[\"response\"][\"video_list\"][\"video\"]['Title']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd11c0a-1810-494d-9b26-0042ff24a551",
   "metadata": {},
   "source": [
    "And finally, we write the titles to a new csv file with other information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c610aa-5022-4b49-b9ff-ee4f4c87fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_names_from_svp(csv_file, upload_csv_file):\n",
    "    rows = []\n",
    "    with open(csv_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "        for row in rows:\n",
    "            if 'Clip ID' in row:            \n",
    "                row['Title'] = get_video_properties(row['Data ID'], token)\n",
    "                \n",
    "        with open(upload_csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=[\"Number\", \"Data ID\", \"Clip ID\",'Mux Asset ID', 'Mux Playback ID', 'Title'])\n",
    "            \n",
    "            # Write the header\n",
    "            writer.writeheader()\n",
    "            \n",
    "            # Write the updated rows\n",
    "            writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773b3b2-23e2-4c9a-9b6a-c58b18849346",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_file_names_from_svp(\"mux_upload.csv\", \"mux_upload_with_names.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e59cc-127f-4e0f-8851-0dcd8275c397",
   "metadata": {},
   "source": [
    "# Extracting subtitles and uploading them to SVP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d478f4-6afa-4561-b99a-e5e40793c041",
   "metadata": {},
   "source": [
    "Firstly, we define the function for fetching the subtitles given the clip_id. This returns the list of subtitles attached to the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33625164-1a6c-42e9-8ee0-fe4acb3834f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_subtitles(clip_id):\n",
    "        url = f\"https://service.webvideocore.net/?l=info&a=xmlClipPath&page_url=https%3A%2F%2Fplay.webvideocore.net%2Fpopplayer.php%3Fit%3D{clip_id}&clip_id={clip_id}\"\n",
    "        response = requests.get(url)\n",
    "        response_text = xmltodict.parse(response.text)\n",
    "        if 'subs' in response_text['links']['info'] and 'sub' in response_text['links']['info']['subs']:            \n",
    "            return response_text['links']['info']['subs']['sub']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f08ef0-af99-46e5-aefc-33f56288717f",
   "metadata": {},
   "source": [
    "Next, we define our language map to map the language label on SVP to the language code recognized by MUX, the language map can be updated to include any language or labels to be used in both svp or mux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d99aa8-b14a-4f26-900c-0abbccc65627",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_map = {\n",
    "        \"English\": \"en-US\",\n",
    "        \"Espa√±ol\": \"es-ES\",\n",
    "        \"Suomi\": \"fi-FI\",\n",
    "        \"Afar\": \"aa-AA\",\n",
    "        \"Deitsch\": \"de-DE\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7bfe52-66e7-4bd6-bd8b-c796272d3a5f",
   "metadata": {},
   "source": [
    "Afterwards, we need to define the function for updating the video with the appropriate list of subtitle tracks on mux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f6de0-87d7-4f65-b75a-9d5a08d5daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_track_to_mux_asset(asset_id, url, mux_token_id, mux_token_secret, language):\n",
    "    language_code = language_map.get(language, \"en-US\")\n",
    "    \n",
    "    api_url = f\"https://api.mux.com/video/v1/assets/{asset_id}/tracks\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"url\": url,\n",
    "        \"type\": \"text\",\n",
    "        \"text_type\": \"subtitles\",\n",
    "        \"closed_captions\": True,\n",
    "        \"language_code\": language_code,\n",
    "        \"name\": language,\n",
    "        \"passthrough\": language\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        api_url,\n",
    "        headers=headers,\n",
    "        json=data,\n",
    "        auth=HTTPBasicAuth(mux_token_id, mux_token_secret)\n",
    "    )\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b02148-fc6f-44cd-8236-7bf050000c31",
   "metadata": {},
   "source": [
    "Now, we put everything together by parsing the csv file, check if a particular video has a subtitle and then upload the subtitle track to Mux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687e8bb-4b38-4279-b1dd-0f06bd32fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_subtitle(csv_file):\n",
    "    rows = []\n",
    "    with open(csv_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if 'Clip ID' in row:  \n",
    "                subtitles = fetch_subtitles(row['Clip ID'])\n",
    "                if subtitles is not None:\n",
    "                    for subtitle in subtitles:\n",
    "                         if subtitle['label'] != \"Off\":\n",
    "                            try:\n",
    "                                add_track_to_mux_asset(row['Mux Asset ID'], \n",
    "                                                       subtitle['link'],\n",
    "                                                       mux_access_keys, \n",
    "                                                       mux_secret_token,\n",
    "                                                       subtitle['label']\n",
    "                                                      )\n",
    "                            except Exception as ex:\n",
    "                                print(ex)\n",
    "                \n",
    "upload_subtitle('mux_upload_with_names.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
